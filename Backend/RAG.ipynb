{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  \\\n",
    "    langchain-pinecone \\\n",
    "    langchain-openai \\\n",
    "    langchain \\\n",
    "    langchain-community \\\n",
    "    pinecone-notebooks\\\n",
    "    pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Using cached pypdf-4.3.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Downloading pypdf-4.3.0-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m16.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf\n",
      "Successfully installed pypdf-4.3.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-cohere\n",
      "  Downloading langchain_cohere-0.1.9-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting cohere<6.0,>=5.5.6 (from langchain-cohere)\n",
      "  Downloading cohere-5.6.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain-cohere) (0.2.20)\n",
      "Requirement already satisfied: langchain-experimental>=0.0.6 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain-cohere) (0.0.62)\n",
      "Requirement already satisfied: pandas>=1.4.3 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langchain-cohere) (2.2.2)\n",
      "Collecting tabulate<0.10.0,>=0.9.0 (from langchain-cohere)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting boto3<2.0.0,>=1.34.0 (from cohere<6.0,>=5.5.6->langchain-cohere)\n",
      "  Downloading boto3-1.34.145-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.5.6->langchain-cohere)\n",
      "  Downloading fastavro-1.9.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.27.0)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from cohere<6.0,>=5.5.6->langchain-cohere)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting parameterized<0.10.0,>=0.9.0 (from cohere<6.0,>=5.5.6->langchain-cohere)\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.7.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (0.19.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (2.32.0.20240712)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from cohere<6.0,>=5.5.6->langchain-cohere) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain-cohere) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain-cohere) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain-cohere) (0.1.88)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain-cohere) (24.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain-cohere) (8.4.2)\n",
      "Requirement already satisfied: langchain-community<0.3.0,>=0.2.6 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain-experimental>=0.0.6->langchain-cohere) (0.2.7)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from pandas>=1.4.3->langchain-cohere) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from pandas>=1.4.3->langchain-cohere) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from pandas>=1.4.3->langchain-cohere) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from pandas>=1.4.3->langchain-cohere) (2024.1)\n",
      "Collecting botocore<1.35.0,>=1.34.145 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere)\n",
      "  Downloading botocore-1.34.145-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain-cohere)\n",
      "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: anyio in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (4.4.0)\n",
      "Requirement already satisfied: certifi in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (3.7)\n",
      "Requirement already satisfied: sniffio in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain-cohere) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain-cohere) (3.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.6->langchain-experimental>=0.0.6->langchain-cohere) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.6->langchain-experimental>=0.0.6->langchain-cohere) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.6->langchain-experimental>=0.0.6->langchain-cohere) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.7 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.6->langchain-experimental>=0.0.6->langchain-cohere) (0.2.9)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain-cohere) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from pydantic>=1.9.2->cohere<6.0,>=5.5.6->langchain-cohere) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from pydantic>=1.9.2->cohere<6.0,>=5.5.6->langchain-cohere) (2.18.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->langchain-cohere) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain-cohere) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (0.23.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain-experimental>=0.0.6->langchain-cohere) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain-experimental>=0.0.6->langchain-cohere) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain-experimental>=0.0.6->langchain-cohere) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain-experimental>=0.0.6->langchain-cohere) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain-experimental>=0.0.6->langchain-cohere) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.6->langchain-experimental>=0.0.6->langchain-cohere) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.6->langchain-experimental>=0.0.6->langchain-cohere) (0.9.0)\n",
      "Requirement already satisfied: filelock in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (2024.6.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain-cohere) (4.66.4)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain<0.3.0,>=0.2.7->langchain-community<0.3.0,>=0.2.6->langchain-experimental>=0.0.6->langchain-cohere) (0.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.3.0,>=0.2.6->langchain-experimental>=0.0.6->langchain-cohere) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.6->langchain-experimental>=0.0.6->langchain-cohere) (1.0.0)\n",
      "Downloading langchain_cohere-0.1.9-py3-none-any.whl (35 kB)\n",
      "Downloading cohere-5.6.1-py3-none-any.whl (178 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.5/178.5 kB\u001b[0m \u001b[31m244.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading boto3-1.34.145-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m304.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading fastavro-1.9.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m383.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Downloading botocore-1.34.145-py3-none-any.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m424.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m716.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tabulate, parameterized, jmespath, httpx-sse, fastavro, botocore, s3transfer, boto3, cohere, langchain-cohere\n",
      "Successfully installed boto3-1.34.145 botocore-1.34.145 cohere-5.6.1 fastavro-1.9.5 httpx-sse-0.4.0 jmespath-1.0.1 langchain-cohere-0.1.9 parameterized-0.9.0 s3transfer-0.10.2 tabulate-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-ai21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3595 document chunks.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "# from langchain_ai21 import AI21Embeddings\n",
    "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the list of PDF file paths\n",
    "pdf_paths = [\n",
    "    \"/home/jericho/Documents/GitHub/deeplearning/projects/mental-health-bot/Backend/documents/9241562579.pdf\",\n",
    "    \"/home/jericho/Documents/GitHub/deeplearning/projects/mental-health-bot/Backend/documents/Counseling and Psychotherapy Theories in Context and Practice, with Video Resource Center_ Skills, Strategies, and Techniques ( PDFDrive ).pdf\",\n",
    "    \"/home/jericho/Documents/GitHub/deeplearning/projects/mental-health-bot/Backend/documents/Handbook of Psychotherapy Case Formulation, Second Edition (Handbook of Psychotherapy Case Formulation) ( PDFDrive ).pdf\",\n",
    "    \"/home/jericho/Documents/GitHub/deeplearning/projects/mental-health-bot/Backend/documents/Introduction to Counselling and Psychotherapy_ The Essential Guide (Counselling in Action Series) ( PDFDrive ).pdf\",\n",
    "    \"/home/jericho/Documents/GitHub/deeplearning/projects/mental-health-bot/Backend/documents/MHGuidebook-EBookDownload.pdf\",\n",
    "    \"/home/jericho/Documents/GitHub/deeplearning/projects/mental-health-bot/Backend/documents/Psychiatric Mental Health Nursing Concepts of Care in Evidence-Based Practice by Mary C. Townsend DSN  PMHCNS-BC (z-lib.org).pdf\",\n",
    "    \"/home/jericho/Documents/GitHub/deeplearning/projects/mental-health-bot/Backend/documents/Self-Therapy_ A Step-By-Step Guide to Creating Wholeness and Healing Your Inner Child Using IFS, A New, Cutting-Edge Psychotherapy ( PDFDrive ).pdf\",\n",
    "    \"/home/jericho/Documents/GitHub/deeplearning/projects/mental-health-bot/Backend/documents/What Is Counselling and Psychotherapy_ (Counselling and Psychotherapy Practice)   ( PDFDrive ).pdf\",\n",
    "    \"/home/jericho/Documents/GitHub/deeplearning/projects/mental-health-bot/Backend/documents/Zen and the Heart of Psychotherapy - Zen Qigong ( PDFDrive ).pdf\"\n",
    "]\n",
    "\n",
    "# Initialize the text splitter with a chunk size less than 2000 characters\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1500, chunk_overlap=0)\n",
    "\n",
    "# Load and split all PDFs\n",
    "all_docs = []\n",
    "for pdf_path in pdf_paths:\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    docs = loader.load_and_split(text_splitter=text_splitter)\n",
    "    all_docs.extend(docs)\n",
    "\n",
    "# Extract text from each document chunk\n",
    "all_texts = [doc.page_content for doc in all_docs]\n",
    "\n",
    "# Verify and further split if necessary\n",
    "def ensure_chunk_size(texts, max_size=2000):\n",
    "    \"\"\"Ensure that each text chunk is under the specified maximum size.\"\"\"\n",
    "    valid_texts = []\n",
    "    for text in texts:\n",
    "        while len(text) > max_size:\n",
    "            valid_texts.append(text[:max_size])\n",
    "            text = text[max_size:]\n",
    "        valid_texts.append(text)\n",
    "    return valid_texts\n",
    "\n",
    "# Ensure each chunk is under the 2000 character limit\n",
    "all_texts = ensure_chunk_size(all_texts)\n",
    "\n",
    "# Initialize the embeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Embed all document texts\n",
    "embedded_docs = embeddings.embed_documents(all_texts)\n",
    "\n",
    "# Print the number of processed document chunks\n",
    "print(f\"Processed {len(all_docs)} document chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=embedded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pinecone_notebooks.colab import Authenticate\n",
    "\n",
    "# Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"test-index\"  \n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pinecone_notebooks.colab import Authenticate\n",
    "\n",
    "# Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"test-index\"  \n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 64}},\n",
       " 'total_vector_count': 64}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "import getpass\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] =  os.getenv(\"PINECONE_API_KEY\")  # get\n",
    "# '1a2097d8-79f1-48d8-bbfc-35e12d082eb2'\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(docs, embeddings, index_name= index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "A stitch in time\n",
      "Psychosocial interventions, such as\n",
      "cognitive-behavioural therapy andfamily-based group intervention for“high risk” children, prevent thedevelopment of anxiety disorders(Dadds et al., 1997) and reducedepressive symptoms and conductproblems (Jaycox et al., 1994).Depression in adolescence has a highrisk of recurrence in adulthood, and isalso associated with the risk of devel-opment of personality problems orconduct disorders. It is possible to prevent the majority \n",
      "of suicides and suicide attemptsamong schoolchildren through a com-prehensive schools-based preventionprogramme that includes appropriatemodiﬁcations to school-based policy,teacher training, parent education,stress management and a life-skillscurriculum, along with the introduc-tion of a crisis team in each school(Zenere & Lazarus, 1997).\n",
      "Veliana, 6 years old, Bulgaria\n"
     ]
    }
   ],
   "source": [
    "query = \"what is Cognitive Therapy\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESTRIEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'mentor',\n",
       " 'result': 'According to the text, the company has two mentors: Caitlin Burns, an accomplished producer based in New York, and Oscar-winning VFX supervisor Dave Stump.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "query = 'mentor'\n",
    "\n",
    "llm = ChatGroq(\n",
    "        temperature=0.4,\n",
    "        # model=\"llama3-groq-8b-8192-tool-use-preview\",\n",
    "        model=\"llama3-70b-8192\",\n",
    "        api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    )\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,  \n",
    "    chain_type=\"stuff\",  \n",
    "    retriever=docsearch.as_retriever()  \n",
    ")  \n",
    "qa(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Set API keys and environment variables\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"PINECONE_API_KEY\"] =  os.getenv(\"PINECONE_API_KEY\")\n",
    "os.environ[\"PINECONE_ENVIRONMENT\"] = 'gcp-starter'\n",
    "\n",
    "INDEX_NAME = \"test-index\"\n",
    "\n",
    "\n",
    "def query_similar_texts(text, count=5):\n",
    "    try:\n",
    "        query_results =PineconeVectorStore.from_existing_index(\n",
    "                index_name=INDEX_NAME,\n",
    "                embedding=OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "            )\n",
    "        texts = query_results.query(text)\n",
    "        return texts\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying similar texts: {e}\")\n",
    "        return None\n",
    " \n",
    "    \n",
    "\n",
    "def retrieve_db(text, count=5):\n",
    "\n",
    "    similar_texts = query_similar_texts(text, count)\n",
    "    return similar_texts\n",
    "\n",
    "\n",
    "# what is a mentor search the retrieve_db tool  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The 2020 World Series was played at Globe Life Field in Arlington, Texas. This was notable because it was the first World Series held at a neutral site due to the COVID-19 pandemic.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Test a simple API call\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The 2020 World Series was played at Globe Life Field in Arlington, Texas. This marked the first time the World Series was held at a neutral site due to the COVID-19 pandemic.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the API key from environment variables\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "#\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG FOR JSON DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "\n",
    "splitter = RecursiveJsonSplitter(max_chunk_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jq\n",
      "  Downloading jq-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Downloading jq-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (664 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.7/664.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jq\n",
      "Successfully installed jq-1.7.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "file_path='/home/jericho/Documents/GitHub/deeplearning/projects/mental-health-bot/Backend/youtube_scraper/YT_TRANSCRIPTS/HealthyGamerGG/HealthyGamerGG_1.json'\n",
    "json_data = json.loads(Path(file_path).read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channel_name': 'HealthyGamerGG',\n",
       " 'video_url': 'https://www.youtube.com/watch?v=I8o2Xzpbqvc',\n",
       " 'video_title': \"Why Men Don't Ask For Help\",\n",
       " 'transcript': \"so this is the first problem when it\\ncomes to help-seeking especially if\\nyou're a man which is that often times\\nwe don't know how to communicate\\neffectively we're incredibly vague with\\nour language we ourselves don't realize\\nwhat kind of help we need and so it puts\\npeople in a very difficult situation\\nwhere when you say I'm stressed and\\noverwhelmed what is that person supposed\\nto do they have no idea and what that\\nsort of means is it's kind of really\\ntricky because if they have no idea what\\nto do you're not giving them a frame to\\nhelp you it makes it difficult for them\\nto help you and the harder you make it\\nfor someone else to help you the less\\nlikely you are to ask for help and if\\nyou don't ask for help and they don't\\nknow how to help then you end up saying\\nthis is absolutely a mess it's never\\ngoing to work nothing good comes of it\\nanyway so I'm done and then we lead to a\\nlife of loneliness isolation and\\neventually getting crushed because life\\nis a multiplayer Co-op game human beings\\nhave evolved to help each other out and\\nas a man if you don't know how to get\\nhelp from other human beings you are\\nplaying at a huge disadvantage\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'channel_name': 'HealthyGamerGG', 'video_url': 'https://www.youtube.com/watch?v=I8o2Xzpbqvc', 'video_title': \"Why Men Don't Ask For Help\"}\n",
      "{'transcript': \"so this is the first problem when it\\ncomes to help-seeking especially if\\nyou're a man which is that often times\\nwe don't know how to communicate\\neffectively we're incredibly vague with\\nour language we ourselves don't realize\\nwhat kind of help we need and so it puts\\npeople in a very difficult situation\\nwhere when you say I'm stressed and\\noverwhelmed what is that person supposed\\nto do they have no idea and what that\\nsort of means is it's kind of really\\ntricky because if they have no idea what\\nto do you're not giving them a frame to\\nhelp you it makes it difficult for them\\nto help you and the harder you make it\\nfor someone else to help you the less\\nlikely you are to ask for help and if\\nyou don't ask for help and they don't\\nknow how to help then you end up saying\\nthis is absolutely a mess it's never\\ngoing to work nothing good comes of it\\nanyway so I'm done and then we lead to a\\nlife of loneliness isolation and\\neventually getting crushed because life\\nis a multiplayer Co-op game human beings\\nhave evolved to help each other out and\\nas a man if you don't know how to get\\nhelp from other human beings you are\\nplaying at a huge disadvantage\"}\n"
     ]
    }
   ],
   "source": [
    "# Recursively split json data - If you need to access/manipulate the smaller json chunks\n",
    "json_chunks = splitter.split_json(json_data=json_data)\n",
    "\n",
    "for chunk in json_chunks[:3]:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"channel_name\": \"HealthyGamerGG\", \"video_url\": \"https://www.youtube.com/watch?v=I8o2Xzpbqvc\", \"video_title\": \"Why Men Don't Ask For Help\"}\n",
      "{\"transcript\": \"so this is the first problem when it\\ncomes to help-seeking especially if\\nyou're a man which is that often times\\nwe don't know how to communicate\\neffectively we're incredibly vague with\\nour language we ourselves don't realize\\nwhat kind of help we need and so it puts\\npeople in a very difficult situation\\nwhere when you say I'm stressed and\\noverwhelmed what is that person supposed\\nto do they have no idea and what that\\nsort of means is it's kind of really\\ntricky because if they have no idea what\\nto do you're not giving them a frame to\\nhelp you it makes it difficult for them\\nto help you and the harder you make it\\nfor someone else to help you the less\\nlikely you are to ask for help and if\\nyou don't ask for help and they don't\\nknow how to help then you end up saying\\nthis is absolutely a mess it's never\\ngoing to work nothing good comes of it\\nanyway so I'm done and then we lead to a\\nlife of loneliness isolation and\\neventually getting crushed because life\\nis a multiplayer Co-op game human beings\\nhave evolved to help each other out and\\nas a man if you don't know how to get\\nhelp from other human beings you are\\nplaying at a huge disadvantage\"}\n"
     ]
    }
   ],
   "source": [
    "# The splitter can also output documents\n",
    "docs = splitter.create_documents(texts=[json_data])\n",
    "\n",
    "# or a list of strings\n",
    "texts = splitter.split_text(json_data=json_data)\n",
    "\n",
    "print(texts[0])\n",
    "print(texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[139, 1192]\n",
      "{\"transcript\": \"so this is the first problem when it\\ncomes to help-seeking especially if\\nyou're a man which is that often times\\nwe don't know how to communicate\\neffectively we're incredibly vague with\\nour language we ourselves don't realize\\nwhat kind of help we need and so it puts\\npeople in a very difficult situation\\nwhere when you say I'm stressed and\\noverwhelmed what is that person supposed\\nto do they have no idea and what that\\nsort of means is it's kind of really\\ntricky because if they have no idea what\\nto do you're not giving them a frame to\\nhelp you it makes it difficult for them\\nto help you and the harder you make it\\nfor someone else to help you the less\\nlikely you are to ask for help and if\\nyou don't ask for help and they don't\\nknow how to help then you end up saying\\nthis is absolutely a mess it's never\\ngoing to work nothing good comes of it\\nanyway so I'm done and then we lead to a\\nlife of loneliness isolation and\\neventually getting crushed because life\\nis a multiplayer Co-op game human beings\\nhave evolved to help each other out and\\nas a man if you don't know how to get\\nhelp from other human beings you are\\nplaying at a huge disadvantage\"}\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the size of the chunks\n",
    "print([len(text) for text in texts][:10])\n",
    "\n",
    "# Reviewing one of these chunks that was bigger we see there is a list object there\n",
    "print(texts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRIAL TWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "Video: Why Men Don't Ask For Help\n",
      "Metadata: {'source': 'https://www.youtube.com/watch?v=I8o2Xzpbqvc', 'channel': 'HealthyGamerGG', 'title': \"Why Men Don't Ask For Help\"}\n",
      "--------------------------------------------------\n",
      "Chunk 2:\n",
      "Transcript: so this is the first problem when it\n",
      "comes to help-seeking especially if\n",
      "you're a man which is that often times\n",
      "we don't know how to communicate\n",
      "effectively we're incredibly vague with\n",
      "our language we ourselves don't realize\n",
      "what kind of help we need and so it puts\n",
      "people in a very difficult situation\n",
      "where when you say I'm stressed and\n",
      "overwhelmed what is that person supposed\n",
      "to do they have no idea and what that\n",
      "sort of means is it's kind of really\n",
      "Metadata: {'source': 'https://www.youtube.com/watch?v=I8o2Xzpbqvc', 'channel': 'HealthyGamerGG', 'title': \"Why Men Don't Ask For Help\"}\n",
      "--------------------------------------------------\n",
      "Chunk 3:\n",
      "sort of means is it's kind of really\n",
      "tricky because if they have no idea what\n",
      "to do you're not giving them a frame to\n",
      "help you it makes it difficult for them\n",
      "to help you and the harder you make it\n",
      "for someone else to help you the less\n",
      "likely you are to ask for help and if\n",
      "you don't ask for help and they don't\n",
      "know how to help then you end up saying\n",
      "this is absolutely a mess it's never\n",
      "going to work nothing good comes of it\n",
      "anyway so I'm done and then we lead to a\n",
      "Metadata: {'source': 'https://www.youtube.com/watch?v=I8o2Xzpbqvc', 'channel': 'HealthyGamerGG', 'title': \"Why Men Don't Ask For Help\"}\n",
      "--------------------------------------------------\n",
      "Chunk 4:\n",
      "anyway so I'm done and then we lead to a\n",
      "life of loneliness isolation and\n",
      "eventually getting crushed because life\n",
      "is a multiplayer Co-op game human beings\n",
      "have evolved to help each other out and\n",
      "as a man if you don't know how to get\n",
      "help from other human beings you are\n",
      "playing at a huge disadvantage\n",
      "Metadata: {'source': 'https://www.youtube.com/watch?v=I8o2Xzpbqvc', 'channel': 'HealthyGamerGG', 'title': \"Why Men Don't Ask For Help\"}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Load JSON data\n",
    "with open('/home/jericho/Documents/GitHub/deeplearning/projects/mental-health-bot/Backend/youtube_scraper/YT_TRANSCRIPTS/HealthyGamerGG/HealthyGamerGG_1.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Preprocess the text\n",
    "text = f\"Video: {data['video_title']}\\n\\nTranscript: {data['transcript']}\"\n",
    "\n",
    "# Create a text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Split the text\n",
    "chunks = text_splitter.split_text(text)\n",
    "\n",
    "# Create Document objects with metadata\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=chunk,\n",
    "        metadata={\n",
    "            \"source\": data['video_url'],\n",
    "            \"channel\": data['channel_name'],\n",
    "            \"title\": data['video_title']\n",
    "        }\n",
    "    ) for chunk in chunks\n",
    "]\n",
    "\n",
    "# Print the results\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"Chunk {i + 1}:\")\n",
    "    print(doc.page_content)\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTION TO HANDLE MULTIPLE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents created: 61270\n",
      "Number of embedded documents: 61270\n",
      "Embedding dimension: 1536\n",
      "Document 1:\n",
      "Content: Video Title: Dr. Stacy Sims: Female-Specific Exercise & Nutrition for Health, Performance & Longevit...\n",
      "Metadata: {'source': 'https://www.youtube.com/watch?v=pZX8ikmWvEU', 'channel': 'hubermanlab', 'title': 'Dr. Stacy Sims: Female-Specific Exercise & Nutrition for Health, Performance & Longevity'}\n",
      "Embedding length: 1536\n",
      "--------------------------------------------------\n",
      "Document 2:\n",
      "Content: Transcript: welcome to the huberman Lab podcast\n",
      "where we discuss science and\n",
      "science-based tools for...\n",
      "Metadata: {'source': 'https://www.youtube.com/watch?v=pZX8ikmWvEU', 'channel': 'hubermanlab', 'title': 'Dr. Stacy Sims: Female-Specific Exercise & Nutrition for Health, Performance & Longevity'}\n",
      "Embedding length: 1536\n",
      "--------------------------------------------------\n",
      "Document 3:\n",
      "Content: and with numerous professional a letic\n",
      "teams Dr Sims has authored more than 100\n",
      "peer-reviewed studie...\n",
      "Metadata: {'source': 'https://www.youtube.com/watch?v=pZX8ikmWvEU', 'channel': 'hubermanlab', 'title': 'Dr. Stacy Sims: Female-Specific Exercise & Nutrition for Health, Performance & Longevity'}\n",
      "Embedding length: 1536\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "def load_json_files(folder_path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Load all JSON files from the specified folder.\n",
    "    \n",
    "    Args:\n",
    "    folder_path (str): Path to the folder containing JSON files.\n",
    "    \n",
    "    Returns:\n",
    "    List[Dict]: A list of dictionaries, each containing data from a JSON file.\n",
    "    \"\"\"\n",
    "    json_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                    json_data.append(data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error decoding JSON from file: {filename}\")\n",
    "    return json_data\n",
    "\n",
    "def process_and_split_json_data(json_data: List[Dict]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Process and split the JSON data into chunks.\n",
    "    \n",
    "    Args:\n",
    "    json_data (List[Dict]): A list of dictionaries containing JSON data.\n",
    "    \n",
    "    Returns:\n",
    "    List[Document]: A list of Document objects, each representing a chunk of text with metadata.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    all_documents = []\n",
    "    \n",
    "    for data in json_data:\n",
    "        # Preprocess the text\n",
    "        text = f\"Video Title: {data['video_title']}\\n\\nChannel: {data['channel_name']}\\n\\nTranscript: {data['transcript']}\"\n",
    "        \n",
    "        # Split the text\n",
    "        chunks = text_splitter.split_text(text)\n",
    "        \n",
    "        # Create Document objects with metadata\n",
    "        documents = [\n",
    "            Document(\n",
    "                page_content=chunk,\n",
    "                metadata={\n",
    "                    \"source\": data['video_url'],\n",
    "                    \"channel\": data['channel_name'],\n",
    "                    \"title\": data['video_title']\n",
    "                }\n",
    "            ) for chunk in chunks\n",
    "        ]\n",
    "        \n",
    "        all_documents.extend(documents)\n",
    "    \n",
    "    return all_documents\n",
    "def embed_documents(documents: List[Document]) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Create embeddings for a list of Document objects.\n",
    "    \n",
    "    Args:\n",
    "    documents (List[Document]): A list of Document objects to embed.\n",
    "    \n",
    "    Returns:\n",
    "    List[List[float]]: A list of embeddings, one for each input Document.\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    # Extract the text content from each Document\n",
    "    texts = [doc.page_content for doc in documents]\n",
    "    \n",
    "    # Create embeddings\n",
    "    embedded_docs = embeddings.embed_documents(texts)\n",
    "    \n",
    "    return embedded_docs\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"youtube_scraper/YT_TRANSCRIPTS/hubermanlab\"\n",
    "    json_data = load_json_files(folder_path)\n",
    "    processed_documents = process_and_split_json_data(json_data)\n",
    "    \n",
    "    print(f\"Total number of documents created: {len(processed_documents)}\")\n",
    "    \n",
    "   # Create embeddings\n",
    "    embedded_docs = embed_documents(processed_documents)\n",
    "    \n",
    "    print(f\"Number of embedded documents: {len(embedded_docs)}\")\n",
    "    print(f\"Embedding dimension: {len(embedded_docs[0])}\")\n",
    "    \n",
    "    # Print the first few documents and their embedding lengths as an example\n",
    "    for i, (doc, embedding) in enumerate(zip(processed_documents[:3], embedded_docs[:3])):\n",
    "        print(f\"Document {i + 1}:\")\n",
    "        print(f\"Content: {doc.page_content[:100]}...\")  # Print first 100 characters\n",
    "        print(f\"Metadata: {doc.metadata}\")\n",
    "        print(f\"Embedding length: {len(embedding)}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"test-index\"  \n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 116}},\n",
       " 'total_vector_count': 116}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_pinecone import PineconeVectorStore\n",
    "# import getpass\n",
    "\n",
    "# os.environ[\"PINECONE_API_KEY\"] =  os.getenv(\"PINECONE_API_KEY\")  # get\n",
    "# # '1a2097d8-79f1-48d8-bbfc-35e12d082eb2'\n",
    "\n",
    "# docsearch = PineconeVectorStore.from_documents(embedded_docs, embeddings, index_name= index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is Cognitive Therapy\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pinecone_index(documents: List[Document], embeddings: List[List[float]], index_name: str) -> PineconeVectorStore:\n",
    "    \"\"\"\n",
    "    Create a Pinecone index from documents and their embeddings.\n",
    "    \n",
    "    Args:\n",
    "    documents (List[Document]): A list of Document objects.\n",
    "    embeddings (List[List[float]]): A list of embeddings corresponding to the documents.\n",
    "    index_name (str): The name of the Pinecone index to create or use.\n",
    "    \n",
    "    Returns:\n",
    "    PineconeVectorStore: The created Pinecone vector store.\n",
    "    \"\"\"\n",
    "    # Ensure PINECONE_API_KEY is set\n",
    "    if \"PINECONE_API_KEY\" not in os.environ:\n",
    "        raise ValueError(\"PINECONE_API_KEY environment variable is not set\")\n",
    "\n",
    "    # Create the Pinecone vector store\n",
    "    embeddings_model = OpenAIEmbeddings()  # We need to pass an embedding model, not the embeddings themselves\n",
    "    docsearch = PineconeVectorStore.from_texts(\n",
    "        texts=[doc.page_content for doc in documents],\n",
    "        embedding=embeddings_model,\n",
    "        metadatas=[doc.metadata for doc in documents],\n",
    "        index_name=index_name\n",
    "    )\n",
    "    \n",
    "    return docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pinecone_index = create_pinecone_index(processed_documents, embedded_docs, index_name)\n",
    "    print(f\"Successfully created Pinecone index: {index_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Pinecone index: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: bad auth : authentication failed, full error: {'ok': 0, 'errmsg': 'bad auth : authentication failed', 'code': 8000, 'codeName': 'AtlasError'}\n"
     ]
    }
   ],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "uri  = \"mongodb+srv://katendejericho5:1EdUVHpXP2OvSGX@wellcarebot.zumm0ya.mongodb.net/?retryWrites=true&w=majority&appName=wellcarebot\"\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "uri = \"mongodb+srv://katendejericho5:mongopassword@wellcarebot.8lklv.mongodb.net/?retryWrites=true&w=majority&appName=wellcarebot\"\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jericho-gZJxJXtS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
