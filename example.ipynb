{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (0.2.7)\n",
      "Requirement already satisfied: langchain_openai in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (0.1.14)\n",
      "Requirement already satisfied: langgraph in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (0.1.5)\n",
      "Requirement already satisfied: requests in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain) (0.2.15)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain) (0.1.83)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain) (2.7.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain) (8.4.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain_openai) (1.35.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from requests) (2024.6.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.12->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.12->langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain) (3.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langgraph in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (0.1.5)\n",
      "Requirement already satisfied: langchain in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (0.2.7)\n",
      "Requirement already satisfied: openai in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (1.35.3)\n",
      "Requirement already satisfied: langchain_openai in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (0.1.14)\n",
      "Requirement already satisfied: langchain_community in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (0.2.7)\n",
      "Requirement already satisfied: pyowm in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (3.3.0)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langgraph) (0.2.15)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain) (0.1.83)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain) (2.7.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain) (8.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: geojson<3,>=2.3.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from pyowm) (2.5.0)\n",
      "Requirement already satisfied: PySocks<2,>=1.7.1 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from pyowm) (1.7.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: certifi in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2->langgraph) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2->langgraph) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib64/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2->langgraph) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/jericho/.local/share/virtualenvs/jericho-gZJxJXtS/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain_openai langgraph requests\n",
    "%pip install langgraph langchain openai langchain_openai langchain_community pyowm\n",
    "%%capture --no-stderr\n",
    "%pip install -U tavily-python\n",
    "%pip install -U langchain_community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: bad assignment\n"
     ]
    }
   ],
   "source": [
    "!export OPENAI_API_KEY='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'\n",
    "\n",
    "!export tavily_api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "# os.environ[\"OPENWEATHERMAP_API_KEY\"] = '39a696bc66feb0b1fa34359d881ddc26'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141',\n",
       "  'content': 'Nodes: Nodes are the building blocks of your LangGraph. Each node represents a function or a computation step. You define nodes to perform specific tasks, such as processing input, making ...'},\n",
       " {'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "  'content': 'LangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. It simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing ...'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# from langchain_community.utilities import OpenWeatherMapAPIWrapper\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "openai_llm = ChatOpenAI(temperature=0.4)\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "\n",
    "\n",
    "tools = [tool]\n",
    "tool.invoke(\"What's a 'node' in LangGraph?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            configuration = config.get(\"configurable\", {})\n",
    "            passenger_id = configuration.get(\"passenger_id\", None)\n",
    "            state = {**state, \"user_info\": passenger_id}\n",
    "            result = self.runnable.invoke(state)\n",
    "            # If the LLM happens to return an empty response, we will re-prompt it\n",
    "            # for an actual response.\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "\n",
    "primary_assistant_prompt  = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a compassionate mental health assistant. Your role is to listen, understand, and offer support. \"\n",
    "            \" Utilize the tools at your disposal to provide information on mental health topics, suggest coping strategies, \"\n",
    "            \" and refer users to professional services when necessary. Always maintain a calm and empathetic demeanor. \"\n",
    "            \" Remember, your goal is to make the user feel understood and less alone. \"\n",
    "            \"\\n\\nCurrent user:\\n\\n{user_info}\\n\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "part_1_tools = [\n",
    "    TavilySearchResults(max_results=1),\n",
    "]\n",
    "part_1_assistant_runnable = primary_assistant_prompt | llm.bind_tools(part_1_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", Assistant(part_1_assistant_runnable))\n",
    "builder.add_node(\"tools\", create_tool_node_with_fallback(part_1_tools))\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# The checkpointer lets the graph persist its state\n",
    "# this is a complete memory for the entire graph.\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "part_1_graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(part_1_graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # The passenger_id is used in our flight tools to\n",
    "        # fetch the user's flight information\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi there, how are you feeling today?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! I'm here to support you. How are you doing today? Is there anything specific on your mind that you'd like to talk about or any support you need?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I've been feeling really anxious lately, any advice?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm sorry to hear that you've been feeling anxious. It's important to remember that you're not alone and there are ways to manage and alleviate anxiety. Here are a few strategies that might help:\n",
      "\n",
      "1. **Breathing Exercises**: Deep breathing can help calm your nervous system and reduce anxiety. Try the 4-7-8 technique: inhale deeply for 4 seconds, hold your breath for 7 seconds, and exhale slowly for 8 seconds.\n",
      "\n",
      "2. **Mindfulness and Meditation**: Practicing mindfulness can help you stay present and reduce anxious thoughts about the past or future. Meditation apps or guided sessions can be a good start.\n",
      "\n",
      "3. **Physical Activity**: Regular exercise can significantly reduce anxiety. It doesn't have to be intense; even a daily walk can make a difference.\n",
      "\n",
      "4. **Limit Stimulants**: Reducing or eliminating caffeine and sugar can help lower anxiety levels for some people.\n",
      "\n",
      "5. **Routine**: Try to establish a daily routine. Consistency can provide a sense of normality and control.\n",
      "\n",
      "6. **Connect with Others**: Talking to friends, family, or joining support groups can provide comfort and reduce feelings of isolation.\n",
      "\n",
      "7. **Journaling**: Writing down your thoughts and feelings can provide an outlet for expressing what's on your mind and help organize your thoughts.\n",
      "\n",
      "8. **Professional Support**: If your anxiety is overwhelming or persistent, it might be helpful to speak with a mental health professional. ... (truncated)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "It sounds like you're going through a tough time. Can you tell me more about what's been happening?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It seems there might be a little confusion, but I'm here to help you. If you're experiencing anxiety or facing challenges, sharing more about your specific situation can help me provide more personalized support. For instance, if there are particular triggers for your anxiety, changes in your life recently, or specific concerns on your mind, feel free to share as much as you're comfortable with. This way, I can offer tailored advice or coping strategies that might be more effective for you. Remember, this is a safe space for you to express your feelings and concerns.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Have you considered talking to a professional about what you're going through?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It's a great idea to consider speaking with a professional about what you're going through. Professionals, such as therapists or counselors, have the training and expertise to offer support and guidance tailored to your specific needs. They can provide a safe and confidential space for you to explore your feelings, understand the roots of your anxiety, and develop strategies to manage it effectively.\n",
      "\n",
      "Seeking professional help can be a significant step towards feeling better. Therapists can employ various approaches, such as Cognitive Behavioral Therapy (CBT), which is particularly effective for anxiety, as well as mindfulness techniques, and other therapeutic methods depending on your individual situation.\n",
      "\n",
      "Here are some steps to get started:\n",
      "\n",
      "1. **Research**: Look for therapists or counselors who specialize in anxiety or the specific issues you're facing. Websites like Psychology Today offer directories where you can filter professionals by location, specialty, and insurance.\n",
      "\n",
      "2. **Insurance and Costs**: Check with your insurance provider to see what mental health services are covered under your plan. If you don't have insurance, some therapists offer sliding scale fees based on income.\n",
      "\n",
      "3. **Make Contact**: Reach out to a few therapists to see if they're accepting new clients and to ask any preliminary questions you might have. Many therapists offer a free initial consultation to see  ... (truncated)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "There are many resources available for people dealing with anxiety. Would you like me to find some for you?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yes, absolutely, I can help with that. To provide you with the most relevant resources, could you let me know your general location or if you're looking for online resources? This will help me tailor the information to better suit your needs. Whether you're interested in finding a therapist, joining a support group, or exploring self-help materials, there are many options available to support you in managing anxiety.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember, it's okay to ask for help. There are people who care about you and want to see you well.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's absolutely right, and it's an important message to hold onto. Reaching out for help is a courageous step and a key part of taking care of your mental health. It's essential to remember that you're not alone in this—many people understand what you're going through and are ready to support you. Whether it's friends, family, or professionals, there's a network of support out there for you. \n",
      "\n",
      "If you're feeling hesitant or unsure about where to start, know that every step towards seeking help, no matter how small it may seem, is a step in the right direction. And if you're not sure how to reach out or what to say, it can be as simple as, \"I've been feeling really anxious lately and I think I need some help.\" People who care about you will want to support you in finding the help you need.\n",
      "\n",
      "If you need assistance in finding specific resources or have any questions about navigating mental health support, please don't hesitate to ask. You deserve support and there are many paths forward to feeling better.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Let's take a moment to breathe deeply. How does that feel?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Taking a moment to focus on your breathing can be a powerful tool for calming the mind and body. As you take a deep breath in, imagine drawing in calmness and peace. Hold that breath for a moment, and as you exhale, envision releasing any tension or anxiety you're feeling. \n",
      "\n",
      "Repeat this a few times at your own pace, allowing each breath to become a bit slower and deeper than the last. Notice the sensations in your body with each breath. Feel the air fill your lungs and then the release of tension as you breathe out.\n",
      "\n",
      "After a few deep breaths, take a moment to notice any changes in how you feel. Do you feel a bit more relaxed or centered? Remember, this simple practice can be a helpful tool whenever you're feeling anxious or stressed.\n",
      "\n",
      "How are you feeling now after taking those deep breaths?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Is there anything specific you'd like to talk about or any particular issue you're facing?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm here to support you, so if there's anything on your mind or any specific issue you're dealing with, feel free to share. Whether it's stress, anxiety, a personal situation, or questions about mental health, I'm here to listen and help as best as I can. Talking about what you're going through can often provide relief and clarity, and together, we can explore strategies or resources that might be beneficial for you. Remember, you're not alone, and it's okay to seek support.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Would you like to explore some relaxation techniques that might help you cope?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Exploring relaxation techniques can be a great way to manage stress and anxiety. Here are a few methods that many people find helpful. Feel free to try them out and see which ones work best for you:\n",
      "\n",
      "1. **Deep Breathing**: A simple yet effective technique. Focus on taking slow, deep breaths. Inhale through your nose, allowing your chest and lower belly to rise, and exhale slowly through your mouth or nose.\n",
      "\n",
      "2. **Progressive Muscle Relaxation (PMR)**: This involves tensing each muscle group in your body tightly, but not to the point of strain, and then slowly relaxing them. Start with your toes and work your way up to your head. This can help reduce physical tension and promote relaxation.\n",
      "\n",
      "3. **Guided Imagery**: Close your eyes and imagine a peaceful place or situation. Engage all your senses to create a vivid mental image. This can help divert your mind from stressors and bring about a sense of tranquility.\n",
      "\n",
      "4. **Mindfulness Meditation**: Sit in a comfortable position and focus your attention on the present moment. When your mind wanders, gently bring it back to your breath or a mantra. This can help calm your mind and reduce anxious thoughts.\n",
      "\n",
      "5. **Yoga**: Combining physical postures, breathing exercises, and meditation, yoga can help reduce stress, lower blood pressure, and improve heart function.\n",
      "\n",
      "6. **Aromatherapy**: Using essential oils can have a calming effect on some people. Lav ... (truncated)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm here to listen. What's on your mind today?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for your openness and readiness to engage. As an AI developed by OpenAI, I'm here to provide support and information. While I can't share personal experiences or feelings, I'm here to listen to what's on your mind and offer guidance or resources that might help you. Whether you have questions, are seeking advice, or just need to talk about what you're going through, feel free to share. I'm here to help in any way I can. What would you like to talk about today?\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import uuid\n",
    "\n",
    "# Mental health conversation flow\n",
    "mental_health_conversation_flow = [\n",
    "    \"Hi there, how are you feeling today?\",\n",
    "    \"I've been feeling really anxious lately, any advice?\",\n",
    "    \"It sounds like you're going through a tough time. Can you tell me more about what's been happening?\",\n",
    "    \"Have you considered talking to a professional about what you're going through?\",\n",
    "    \"There are many resources available for people dealing with anxiety. Would you like me to find some for you?\",\n",
    "    \"Remember, it's okay to ask for help. There are people who care about you and want to see you well.\",\n",
    "    \"Let's take a moment to breathe deeply. How does that feel?\",\n",
    "    \"Is there anything specific you'd like to talk about or any particular issue you're facing?\",\n",
    "    \"Would you like to explore some relaxation techniques that might help you cope?\",\n",
    "    \"I'm here to listen. What's on your mind today?\",\n",
    "]\n",
    "\n",
    "\n",
    "_printed = set()\n",
    "for question in mental_health_conversation_flow:\n",
    "    events = part_1_graph.stream(\n",
    "        {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)\n",
    "\n",
    "def _print_event(event, printed_events):\n",
    "    if event not in printed_events:\n",
    "        print(f\"Event: {event['message']}, Timestamp: {event['timestamp']}\")\n",
    "        printed_events.add(event)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jericho-gZJxJXtS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
